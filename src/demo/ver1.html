<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Face Landmarks - TensorFlow.js + MediaPipe GPU</title>
  <style>
    html,body { height:100%; margin:0; background:#111; display:flex; align-items:center; justify-content:center; }
    #container { position:relative; width: 100%; max-width: 960px; }
    video { display:none; } /* 生映像は canvas 上に描画するので非表示 */
    canvas { width:100%; height:auto; display:block; background:#000; border-radius:8px; }
    #status { color:#ddd; font-family:monospace; margin-top:8px; }
  </style>
</head>
<body>
  <div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="output"></canvas>
    <div id="status">初期化中...</div>
  </div>

  <!-- 必須の依存ライブラリ -->
  <!-- 1. tfjs-core -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>
  <!-- 2. tfjs-backend-webgl -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.22.0"></script>
  <!-- 3. MediaPipe FaceMesh -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <!-- 4. Face Landmarks Detection (UMD) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection/dist/face-landmarks-detection.js"></script>

  <script type="module">
  window.addEventListener('load', function () {
  (async () => {
    const statusEl = document.getElementById('status');
    const video = document.getElementById('video');
    const canvas = document.getElementById('output');
    const ctx = canvas.getContext('2d', { willReadFrequently: false });

    // 解像度設定（希望する最大幅）
    const targetWidth = 960;
    const maxFaces = 6;

    // WebGL バックエンドを選択して初期化
    await tf.setBackend('webgl');
    await tf.ready();

    statusEl.textContent = 'カメラ取得中...';
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user', width: { ideal: targetWidth }, height: { ideal: 720 } },
        audio: false
      });
      video.srcObject = stream;
    } catch (e) {
      statusEl.textContent = 'カメラを開けません: ' + e.message;
      throw e;
    }

    // video のメタデータ読み込み待ち（サイズ確定）
    await new Promise(resolve => {
      if (video.readyState >= 2) return resolve();
      video.onloadedmetadata = () => resolve();
    });

    // 高DPI対応
    const dpr = Math.max(1, window.devicePixelRatio || 1);
    canvas.width = Math.round(video.videoWidth * dpr);
    canvas.height = Math.round(video.videoHeight * dpr);
    canvas.style.width = video.videoWidth + 'px';
    canvas.style.height = video.videoHeight + 'px';
    ctx.scale(dpr, dpr);

    // モデル読み込み: MediaPipe runtime（GPU を内部で利用）
    statusEl.textContent = 'モデル読み込み中...';
    const model = await faceLandmarksDetection.load(
      faceLandmarksDetection.SupportedPackages.mediapipeFaceMesh,
      {
        maxFaces: maxFaces,
        runtime: 'mediapipe',
        solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js'
      }
    );

    statusEl.textContent = '検出開始';
    video.play();

    // 描画パラメータ
    const landmarkRadius = 10; // px
    const landmarkColor = '#FF0000';

    // メインループ
    async function renderLoop() {
      if (video.paused || video.ended) {
        requestAnimationFrame(renderLoop);
        return;
      }

      // ビデオフレームをキャンバスに描画（下地）
      ctx.clearRect(0, 0, canvas.width / dpr, canvas.height / dpr);
      ctx.drawImage(video, 0, 0, video.videoWidth, video.videoHeight);

      // 推論（非ブロッキングにしたい場合は別処理だがここはシンプルかつ確実）
      let predictions = [];
      try {
        predictions = await model.estimateFaces({input: video, returnTensors: false, flipHorizontal: true});
      } catch (err) {
        // 推論エラーは無視して次フレームへ
        console.warn('estimateFaces error', err);
      }

      // 各顔ごとにランドマークを描画
      ctx.save();
      ctx.fillStyle = landmarkColor;
      ctx.strokeStyle = landmarkColor;
      ctx.lineWidth = 1;

      for (const p of predictions) {
        // p.scaledMesh は [x, y, z] の配列群
        const mesh = p.scaledMesh || p.mesh || [];

        for (let i = 0; i < mesh.length; i++) {
          const kp = mesh[i];
          // MediaPipe の座標はすでにピクセル座標の場合が多いが、
          // 確実を期して video のサイズにマッピングする。
          const x = kp[0];
          const y = kp[1];

          // 円を描く
          ctx.beginPath();
          ctx.arc(x, y, landmarkRadius, 0, Math.PI * 2);
          ctx.fill();
        }
      }
      ctx.restore();

      requestAnimationFrame(renderLoop);
    }

    requestAnimationFrame(renderLoop);

    // ウィンドウリサイズでキャンバスサイズ更新（単純再設定）
    window.addEventListener('resize', () => {
      const newDpr = Math.max(1, window.devicePixelRatio || 1);
      canvas.width = Math.round(video.videoWidth * newDpr);
      canvas.height = Math.round(video.videoHeight * newDpr);
      canvas.style.width = video.videoWidth + 'px';
      canvas.style.height = video.videoHeight + 'px';
      ctx.setTransform(newDpr, 0, 0, newDpr, 0, 0);
    });

  })().catch(err => {
    console.error(err);
    const s = document.getElementById('status');
    if (s) s.textContent = 'エラー: ' + (err && err.message ? err.message : err);
  });
  });
  </script>
</body>
</html>